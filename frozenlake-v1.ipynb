{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "from lib.params import Params\n",
    "from lib.agent import QLearningAgent\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 10_000\n",
    "initial_epsilon = 1\n",
    "\n",
    "params = Params(\n",
    "    total_episodes=total_episodes,\n",
    "    learning_rate=0.8,\n",
    "    discount_factor=0.95,\n",
    "    initial_epsilon=initial_epsilon,\n",
    "    epsilon_decay=initial_epsilon / (total_episodes / 2), # reduce the exploration over time\n",
    "    final_epsilon=0.1,\n",
    "    is_slippery=False,\n",
    "    n_runs=20,\n",
    "    action_size=None,\n",
    "    state_size=None,\n",
    "    proba_frozen=0.9,\n",
    "    savefig_folder=Path(\"fig/frozenlake-v1/\"),\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# create the figure folder if it doesn't exists\n",
    "params.savefig_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env: gym.Env, agent: QLearningAgent):\n",
    "    rewards = np.zeros((params.total_episodes, params.n_runs))\n",
    "    steps = np.zeros((params.total_episodes, params.n_runs))\n",
    "    episodes = np.arange(params.total_episodes)\n",
    "    qtables = np.zeros((params.n_runs, params.state_size, params.action_size))\n",
    "    all_states = []\n",
    "    all_actions = []\n",
    "\n",
    "    for run in range(params.n_runs):  # run several times to account for stochasticity\n",
    "        agent.reset_qtable()  # reset the Q-table between runs\n",
    "\n",
    "        for episode in tqdm(\n",
    "            episodes, desc=f\"Run {run}/{params.n_runs} - Episodes\", leave=False\n",
    "        ):\n",
    "            state = env.reset(seed=params.seed)[0]  # Reset the environment\n",
    "            step = 0\n",
    "            done = False\n",
    "            total_rewards = 0\n",
    "\n",
    "            # play episode\n",
    "            while not done:\n",
    "                action = agent.get_action(\n",
    "                     state=state, \n",
    "                     action_space=env.action_space\n",
    "                )\n",
    "\n",
    "                # log all states and actions\n",
    "                all_states.append(state)\n",
    "                all_actions.append(action)\n",
    "\n",
    "                # take the action (a) and observe the outcome state(s') and reward (r)\n",
    "                new_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "                done = terminated or truncated\n",
    "\n",
    "                # update the agent\n",
    "                agent.update(\n",
    "                    state=state, \n",
    "                    action=action, \n",
    "                    reward=reward,\n",
    "                    terminated=terminated, \n",
    "                    new_state=new_state\n",
    "                )\n",
    "\n",
    "                total_rewards += reward\n",
    "                step += 1\n",
    "\n",
    "                # new state is now state\n",
    "                state = new_state\n",
    "\n",
    "            # log all rewards and steps\n",
    "            rewards[episode, run] = total_rewards\n",
    "            steps[episode, run] = step\n",
    "        qtables[run, :, :] = agent.qtable\n",
    "\n",
    "    return rewards, steps, episodes, qtables, all_states, all_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
